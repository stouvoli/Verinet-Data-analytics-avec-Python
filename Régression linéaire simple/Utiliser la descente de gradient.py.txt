import random
import tqdm
from gradient_descent import gradient_step
num_epochs = 10000
random.seed(0)
# choisir une valeur aléatoire pour démarrer
guess = [random.random(), random.random()]
learning_rate = 0.00001
with tqdm.trange(num_epochs) as t:
  for _ in t:
    alpha, beta = guess
    # dérivée partielle de perte par rapport à alpha
    grad_a = sum(2 * error(alpha, beta, x_i, y_i) for x_i, y_i in 
                 zip(num_friends_good, daily_minutes_good))
    # dérivée partielle de perte par rapport à bêta
    grad_b = sum(2 * error(alpha, beta, x_i, y_i) * x_i for x_i, y_i in 
                 zip(num_friends_good, daily_minutes_good))
    # calculer la perte pour coller à la description tqdm
    loss = sum_of_sqerrors(alpha, beta, num_friends_good, daily_minutes_good)
    t.set_description(f"loss: {loss:.3f}")
    # enfin actualiser la prévision
    guess = gradient_step(guess, [grad_a, grad_b], -learning_rate)
    # nous devrions obtenir pratiquement les mêmes résultats
    alpha, beta = guess
assert 22.9 < alpha < 23.0
assert 0.9 < beta < 0.905
