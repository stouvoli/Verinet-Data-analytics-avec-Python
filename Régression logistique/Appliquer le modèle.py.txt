from machine_learning import train_test_split
from working_with_data import rescale
from gradient_descent import gradient_step
import random
import tqdm
random.seed(0)
rescaled_xs = rescale(xs)
x_train, x_test, y_train, y_test = train_test_split(rescaled_xs, ys, 0.33)
learning_rate = 0.01
# choisir un point de départ aléatoire
beta = [random.random() for _ in range(3)]
with tqdm.trange(5000) as t:
 for étape in t:
  gradient = negative_log_gradient(x_train, y_train, beta)
  beta = gradient_step(beta, gradient, -learning_rate)
  loss = negative_log_likelihood(x_train, y_train, beta)
  t.set_description(f"loss: {loss:.3f} beta: {beta}")